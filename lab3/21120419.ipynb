{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKC04FZL1BKd"
      },
      "source": [
        "#Import relevant modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JwnaK2-G0-MA"
      },
      "outputs": [],
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting.\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imoZshLA1Kgp"
      },
      "source": [
        "#Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u5Z3bFyO1KNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c218e59-f134-4fbd-af15-433c34713503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz5LMAE31S4q"
      },
      "source": [
        "#View the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "wRPcViiX1SpL",
        "outputId": "36f8337b-d575-4a2f-f3d1-8aa88719c0d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 127, 100, 156, 239, 224, 177, 213, 159,  70,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 110, 250, 254, 254, 254, 254, 254, 254, 254, 254, 184,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 216, 254, 254, 254, 254, 254, 254, 254, 254, 254, 251,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   3, 131, 197,  68, 137, 101,  83,  41,  70, 221, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 254,  24,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  83, 247, 254, 192,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 124, 254, 254, 250,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 178, 250, 254, 254, 254, 252, 178, 128,  50,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 252, 254, 254, 254, 254, 254, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 252, 254, 241, 241, 254, 247, 252, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68,  82,   5,   5,  82,  37,  65, 167, 254, 190,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 172, 253,  75,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 254, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 230, 216,  20,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  71, 222, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 254, 254, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,  34,  34,  78, 161, 226, 249, 254, 154,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  96, 184, 254, 254, 254, 254, 254, 249,  93,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-46c0fb90-63a3-4fcf-8e7c-5aa8ab3f595c\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGEqAEcaof2oR/PGiyqnlxz9jKMr79Q8KdnBhSN6Ayf37bQYXZILS2q3H3brTQ7U97jObYeiEA6t/N7jRdcKBCYMaLw59LMHf/x3AdBEDAwMDg2rNv3+/9LFKFW769e/fvz+bGoww5Vz/wHwzE9NBHgwMnz8z/PyH3UaXIFbWIFXH5f/24XAuAwPDImzGQgEj1/9NODWm/ZuBU07t2Q0RHFKM7vf+9eHS5/Tv31wswixKSn4LH/38N4sNUy5hx79///79+xnLitM1pAAACDhcuN3dt1kAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 127, 100, 156, 239, 224, 177, 213, 159,  70,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 110, 250, 254, 254, 254, 254, 254, 254, 254, 254, 184,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 216, 254, 254, 254, 254, 254, 254, 254, 254, 254, 251,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   3, 131, 197,  68, 137, 101,  83,  41,  70, 221, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 254,  24,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  83, 247, 254, 192,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 124, 254, 254, 250,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 178, 250, 254, 254, 254, 252, 178, 128,  50,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 252, 254, 254, 254, 254, 254, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 252, 254, 241, 241, 254, 247, 252, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68,  82,   5,   5,  82,  37,  65, 167, 254, 190,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 172, 253,  75,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 254, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 230, 216,  20,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  71, 222, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 254, 254, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,  34,  34,  78, 161, 226, 249, 254, 154,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  96, 184, 254, 254, 254, 254, 254, 249,  93,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-46c0fb90-63a3-4fcf-8e7c-5aa8ab3f595c button').onclick = (e) => {\n",
              "        document.querySelector('#id-46c0fb90-63a3-4fcf-8e7c-5aa8ab3f595c').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-46c0fb90-63a3-4fcf-8e7c-5aa8ab3f595c button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Output example #2917 of the training set.\n",
        "x_train[2917]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "44fYr9DL1bAY",
        "outputId": "c18d5a66-1c5e-4210-85b8-9491a18d3d68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7db220a45ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Use false colors to visualize the array.\n",
        "plt.imshow(x_train[2917])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNzpwqbx1dvY",
        "outputId": "73484af1-dc70-4d33-b74f-1979d7f7b405"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Output row #10 of example #2917.\n",
        "x_train[2917][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHTBOmlC1hF7",
        "outputId": "e28ed23d-c267-4b05-eea7-3f952351656f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Output pixel #16 of row #10 of example #2900.\n",
        "x_train[2900][10][16]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpkz3qFA1n-G"
      },
      "source": [
        "#Task 1: Normalize feature values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIQ9eZhS1izD",
        "outputId": "a7e76066-19a7-4561-b8f1-38958ad7fd2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.         0.         0.         0.55294118 1.         0.66666667 0.11372549 0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "x_train_normalized = x_train / 255.0\n",
        "x_test_normalized = x_test / 255.0\n",
        "print(x_train_normalized[2900][10]) # Output a normalized row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggsewPCy2S_C"
      },
      "source": [
        "#Define a plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3amWBEP2Wys",
        "outputId": "f4b27fae-0297-45f8-fd23-929b070d2787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the plot_curve function.\n"
          ]
        }
      ],
      "source": [
        "#@title Define the plotting function\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"\n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATwTE00i2d26"
      },
      "source": [
        "#Create a deep neural net model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gAlesTnG2gwK"
      },
      "outputs": [],
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "\n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array.\n",
        "  # Flatten that two-dimensional array into a one-dimensional\n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.\n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "  # Define a dropout regularization layer.\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True,\n",
        "                      validation_split=validation_split)\n",
        "\n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW1Nh6bX2oQp"
      },
      "source": [
        "#Invoke the previous functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-vOiMlKH2tT8",
        "outputId": "5138edcf-c419-413b-d4fc-2a17842186bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 1.7838 - accuracy: 0.4089 - val_loss: 1.0727 - val_accuracy: 0.7698\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.9732 - accuracy: 0.7191 - val_loss: 0.5737 - val_accuracy: 0.8587\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.6753 - accuracy: 0.7982 - val_loss: 0.4288 - val_accuracy: 0.8879\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.5520 - accuracy: 0.8357 - val_loss: 0.3665 - val_accuracy: 0.9007\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4829 - accuracy: 0.8577 - val_loss: 0.3301 - val_accuracy: 0.9103\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4363 - accuracy: 0.8714 - val_loss: 0.3036 - val_accuracy: 0.9160\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.4047 - accuracy: 0.8822 - val_loss: 0.2867 - val_accuracy: 0.9208\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3847 - accuracy: 0.8868 - val_loss: 0.2713 - val_accuracy: 0.9256\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3649 - accuracy: 0.8925 - val_loss: 0.2579 - val_accuracy: 0.9284\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3473 - accuracy: 0.8973 - val_loss: 0.2473 - val_accuracy: 0.9313\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3362 - accuracy: 0.9007 - val_loss: 0.2391 - val_accuracy: 0.9344\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3249 - accuracy: 0.9047 - val_loss: 0.2303 - val_accuracy: 0.9357\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3148 - accuracy: 0.9079 - val_loss: 0.2232 - val_accuracy: 0.9378\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3043 - accuracy: 0.9112 - val_loss: 0.2170 - val_accuracy: 0.9379\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.2962 - accuracy: 0.9121 - val_loss: 0.2117 - val_accuracy: 0.9397\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.2903 - accuracy: 0.9148 - val_loss: 0.2056 - val_accuracy: 0.9422\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.2823 - accuracy: 0.9173 - val_loss: 0.2005 - val_accuracy: 0.9434\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2777 - accuracy: 0.9171 - val_loss: 0.1960 - val_accuracy: 0.9441\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2703 - accuracy: 0.9194 - val_loss: 0.1922 - val_accuracy: 0.9449\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2678 - accuracy: 0.9208 - val_loss: 0.1895 - val_accuracy: 0.9457\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2601 - accuracy: 0.9227 - val_loss: 0.1864 - val_accuracy: 0.9470\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2552 - accuracy: 0.9249 - val_loss: 0.1806 - val_accuracy: 0.9482\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.2522 - accuracy: 0.9247 - val_loss: 0.1784 - val_accuracy: 0.9480\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2439 - accuracy: 0.9270 - val_loss: 0.1747 - val_accuracy: 0.9495\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2432 - accuracy: 0.9272 - val_loss: 0.1723 - val_accuracy: 0.9498\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.2365 - accuracy: 0.9304 - val_loss: 0.1692 - val_accuracy: 0.9517\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2332 - accuracy: 0.9316 - val_loss: 0.1678 - val_accuracy: 0.9514\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.2296 - accuracy: 0.9310 - val_loss: 0.1652 - val_accuracy: 0.9527\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.2262 - accuracy: 0.9327 - val_loss: 0.1627 - val_accuracy: 0.9529\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 0.2230 - accuracy: 0.9333 - val_loss: 0.1611 - val_accuracy: 0.9530\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 0.2187 - accuracy: 0.9347 - val_loss: 0.1602 - val_accuracy: 0.9535\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.2198 - accuracy: 0.9340 - val_loss: 0.1574 - val_accuracy: 0.9546\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.2176 - accuracy: 0.9334 - val_loss: 0.1560 - val_accuracy: 0.9549\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2149 - accuracy: 0.9350 - val_loss: 0.1537 - val_accuracy: 0.9557\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2120 - accuracy: 0.9359 - val_loss: 0.1539 - val_accuracy: 0.9544\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2072 - accuracy: 0.9374 - val_loss: 0.1523 - val_accuracy: 0.9560\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2064 - accuracy: 0.9376 - val_loss: 0.1501 - val_accuracy: 0.9563\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2051 - accuracy: 0.9388 - val_loss: 0.1496 - val_accuracy: 0.9570\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2018 - accuracy: 0.9389 - val_loss: 0.1489 - val_accuracy: 0.9573\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2012 - accuracy: 0.9384 - val_loss: 0.1488 - val_accuracy: 0.9572\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1974 - accuracy: 0.9404 - val_loss: 0.1459 - val_accuracy: 0.9582\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1977 - accuracy: 0.9403 - val_loss: 0.1458 - val_accuracy: 0.9572\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1948 - accuracy: 0.9417 - val_loss: 0.1442 - val_accuracy: 0.9590\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1921 - accuracy: 0.9414 - val_loss: 0.1430 - val_accuracy: 0.9578\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1907 - accuracy: 0.9417 - val_loss: 0.1420 - val_accuracy: 0.9582\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1902 - accuracy: 0.9409 - val_loss: 0.1443 - val_accuracy: 0.9594\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1885 - accuracy: 0.9425 - val_loss: 0.1414 - val_accuracy: 0.9592\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1896 - accuracy: 0.9416 - val_loss: 0.1394 - val_accuracy: 0.9598\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1835 - accuracy: 0.9449 - val_loss: 0.1392 - val_accuracy: 0.9599\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1840 - accuracy: 0.9439 - val_loss: 0.1388 - val_accuracy: 0.9608\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.9599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1419038027524948, 0.9599000215530396]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train,\n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5BkTIwL24ro"
      },
      "source": [
        "#Task 2: Optimize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqHo-_pj24bp"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view some possible answers.\n",
        "\n",
        "# It would take much too long to experiment\n",
        "# fully with topography and dropout regularization\n",
        "# rate. In the real world, you would\n",
        "# also experiment with learning rate, batch size,\n",
        "# and number of epochs.  Since you only have a\n",
        "# few minutes, searching for trends can be helpful.\n",
        "# Here is what we discovered:\n",
        "#   * Adding more nodes (at least until 256 nodes)\n",
        "#     to the first hidden layer improved accuracy.\n",
        "#   * Adding a second hidden layer generally\n",
        "#     improved accuracy.\n",
        "#   * When the model contains a lot of nodes,\n",
        "#     the model overfits unless the dropout rate\n",
        "#     is at least 0.5.\n",
        "\n",
        "# We reached 98% test accuracy with the\n",
        "# following configuration:\n",
        "#   * One hidden layer of 256 nodes; no second\n",
        "#     hidden layer.\n",
        "#   * dropout regularization rate of 0.4\n",
        "\n",
        "# We reached 98.2% test accuracy with the\n",
        "# following configuration:\n",
        "#   * First hidden layer of 256 nodes;\n",
        "#     second hidden layer of 128 nodes.\n",
        "#   * dropout regularization rate of 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WSanR4RITXN4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "learning_rate = 0.003\n",
        "num_epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "input_shape = x_train_normalized.shape[1]\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train_encoded = to_categorical(y_train, 10)\n",
        "y_test_encoded = to_categorical(y_test, 10)\n",
        "\n",
        "# Verify the updated shape of y_train_encoded\n",
        "print(\"Updated shape of y_train_encoded:\", y_train_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SegelZQr7U2N",
        "outputId": "294d8a28-813a-422e-fe95-5e902b52cd51"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated shape of y_train_encoded: (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuration 1"
      ],
      "metadata": {
        "id": "qCUr9zUf7ZdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SL28swUsRQ8n"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model_con1(input_shape, learning_rate, drop_out):\n",
        "  \"\"\"\"create and complie a cnn.\"\"\"\n",
        "\n",
        "  # All models in this course are sequential.\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu', input_shape=(input_shape,)))\n",
        "  model.add(Dropout(drop_out))\n",
        "  model.add(Dense(units=10, activation='softmax'))\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration 1: One hidden layer of 256 nodes; no second hidden layer; dropout rate of 0.4\n",
        "drop_out = 0.4\n",
        "model1 = create_cnn_model_con1(input_shape, learning_rate, drop_out)\n",
        "epochs, hist = train_model(model1, x_train_normalized, y_train_encoded, num_epochs, batch_size, validation_split)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "test_loss1, test_accuracy1 = model1.evaluate(x_test_normalized, y_test_encoded, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3B6ygr2eM53",
        "outputId": "54959767-3653-4ef6-b049-91c7e56da879"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 2s 101ms/step - loss: 1.0714 - accuracy: 0.6720 - val_loss: 0.3849 - val_accuracy: 0.8867\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.4290 - accuracy: 0.8694 - val_loss: 0.2839 - val_accuracy: 0.9192\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.3214 - accuracy: 0.9038 - val_loss: 0.2371 - val_accuracy: 0.9344\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.2676 - accuracy: 0.9225 - val_loss: 0.2021 - val_accuracy: 0.9439\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.2327 - accuracy: 0.9324 - val_loss: 0.1816 - val_accuracy: 0.9482\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 1s 78ms/step - loss: 0.2076 - accuracy: 0.9405 - val_loss: 0.1639 - val_accuracy: 0.9535\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.1867 - accuracy: 0.9466 - val_loss: 0.1502 - val_accuracy: 0.9562\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.1714 - accuracy: 0.9504 - val_loss: 0.1397 - val_accuracy: 0.9593\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.1569 - accuracy: 0.9536 - val_loss: 0.1329 - val_accuracy: 0.9610\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 2s 137ms/step - loss: 0.1477 - accuracy: 0.9559 - val_loss: 0.1241 - val_accuracy: 0.9633\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 0.1363 - accuracy: 0.9606 - val_loss: 0.1185 - val_accuracy: 0.9640\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.1273 - accuracy: 0.9641 - val_loss: 0.1121 - val_accuracy: 0.9665\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 1s 114ms/step - loss: 0.1185 - accuracy: 0.9660 - val_loss: 0.1080 - val_accuracy: 0.9676\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 1s 109ms/step - loss: 0.1127 - accuracy: 0.9675 - val_loss: 0.1035 - val_accuracy: 0.9685\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 1s 125ms/step - loss: 0.1047 - accuracy: 0.9692 - val_loss: 0.1005 - val_accuracy: 0.9706\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 0.1001 - accuracy: 0.9706 - val_loss: 0.0971 - val_accuracy: 0.9712\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.0959 - accuracy: 0.9724 - val_loss: 0.0948 - val_accuracy: 0.9709\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 0.0908 - accuracy: 0.9733 - val_loss: 0.0927 - val_accuracy: 0.9710\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 1s 116ms/step - loss: 0.0869 - accuracy: 0.9751 - val_loss: 0.0900 - val_accuracy: 0.9723\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 0.0830 - accuracy: 0.9760 - val_loss: 0.0879 - val_accuracy: 0.9727\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 2s 142ms/step - loss: 0.0798 - accuracy: 0.9765 - val_loss: 0.0870 - val_accuracy: 0.9728\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 1s 123ms/step - loss: 0.0762 - accuracy: 0.9769 - val_loss: 0.0851 - val_accuracy: 0.9737\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 2s 171ms/step - loss: 0.0722 - accuracy: 0.9795 - val_loss: 0.0821 - val_accuracy: 0.9751\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 2s 149ms/step - loss: 0.0673 - accuracy: 0.9805 - val_loss: 0.0824 - val_accuracy: 0.9740\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 0.0659 - accuracy: 0.9802 - val_loss: 0.0814 - val_accuracy: 0.9743\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 1s 78ms/step - loss: 0.0635 - accuracy: 0.9813 - val_loss: 0.0803 - val_accuracy: 0.9758\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.0598 - accuracy: 0.9830 - val_loss: 0.0775 - val_accuracy: 0.9764\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.0779 - val_accuracy: 0.9763\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 1s 123ms/step - loss: 0.0577 - accuracy: 0.9827 - val_loss: 0.0763 - val_accuracy: 0.9760\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 2s 142ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.0761 - val_accuracy: 0.9771\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0746 - val_accuracy: 0.9771\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 1s 78ms/step - loss: 0.0513 - accuracy: 0.9844 - val_loss: 0.0756 - val_accuracy: 0.9768\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0491 - accuracy: 0.9855 - val_loss: 0.0756 - val_accuracy: 0.9770\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0480 - accuracy: 0.9858 - val_loss: 0.0732 - val_accuracy: 0.9774\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.0740 - val_accuracy: 0.9768\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 0.0457 - accuracy: 0.9861 - val_loss: 0.0724 - val_accuracy: 0.9776\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 0.0730 - val_accuracy: 0.9777\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.0726 - val_accuracy: 0.9781\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.0739 - val_accuracy: 0.9781\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0721 - val_accuracy: 0.9780\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 1s 127ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 0.0721 - val_accuracy: 0.9785\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 2s 140ms/step - loss: 0.0369 - accuracy: 0.9894 - val_loss: 0.0721 - val_accuracy: 0.9789\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.0708 - val_accuracy: 0.9793\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0349 - accuracy: 0.9897 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 0.0343 - accuracy: 0.9895 - val_loss: 0.0710 - val_accuracy: 0.9792\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0697 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.0713 - val_accuracy: 0.9809\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0715 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0714 - val_accuracy: 0.9805\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0652 - accuracy: 0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuration 2"
      ],
      "metadata": {
        "id": "AA7eanMX7pJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model_con2(input_shape, learning_rate, drop_out):\n",
        "  \"\"\"\"create and complie a cnn.\"\"\"\n",
        "\n",
        "  # All models in this course are sequential.\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu', input_shape=(input_shape,)))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(drop_out))\n",
        "  model.add(Dense(units=10, activation='softmax'))\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "yl7y5Y6T7oGu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration 2: First hidden layer of 256 nodes; second hidden layer of 128 nodes; dropout rate of 0.2\n",
        "drop_out = 0.2\n",
        "model2 = create_cnn_model_con2(input_shape, learning_rate, drop_out)\n",
        "epochs, hist = train_model(model2, x_train_normalized, y_train_encoded, num_epochs, batch_size, validation_split)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "test_loss2, test_accuracy2 = model2.evaluate(x_test_normalized, y_test_encoded, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgo55DYweQSS",
        "outputId": "6f30c16c-dafc-40fc-cad9-1f5c816dff68"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 2s 116ms/step - loss: 0.9981 - accuracy: 0.6966 - val_loss: 0.3386 - val_accuracy: 0.9014\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.3545 - accuracy: 0.8945 - val_loss: 0.2424 - val_accuracy: 0.9277\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.2532 - accuracy: 0.9254 - val_loss: 0.1866 - val_accuracy: 0.9451\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 1s 114ms/step - loss: 0.1967 - accuracy: 0.9423 - val_loss: 0.1594 - val_accuracy: 0.9532\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 2s 143ms/step - loss: 0.1615 - accuracy: 0.9518 - val_loss: 0.1382 - val_accuracy: 0.9587\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 0.1377 - accuracy: 0.9590 - val_loss: 0.1244 - val_accuracy: 0.9612\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.1205 - accuracy: 0.9640 - val_loss: 0.1189 - val_accuracy: 0.9646\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.1098 - val_accuracy: 0.9663\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.0912 - accuracy: 0.9731 - val_loss: 0.1021 - val_accuracy: 0.9688\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0819 - accuracy: 0.9758 - val_loss: 0.0954 - val_accuracy: 0.9701\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.0710 - accuracy: 0.9792 - val_loss: 0.0921 - val_accuracy: 0.9723\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.0628 - accuracy: 0.9811 - val_loss: 0.0915 - val_accuracy: 0.9725\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0562 - accuracy: 0.9835 - val_loss: 0.0854 - val_accuracy: 0.9743\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 0.0888 - val_accuracy: 0.9735\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 2s 145ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.0841 - val_accuracy: 0.9753\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 2s 142ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.0804 - val_accuracy: 0.9764\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.0838 - val_accuracy: 0.9769\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.0795 - val_accuracy: 0.9767\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 0.0802 - val_accuracy: 0.9771\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 0.0798 - val_accuracy: 0.9765\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 1s 97ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0812 - val_accuracy: 0.9777\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 2s 136ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.0838 - val_accuracy: 0.9773\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 2s 134ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0837 - val_accuracy: 0.9767\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.0847 - val_accuracy: 0.9771\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 1s 121ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.0866 - val_accuracy: 0.9763\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 2s 141ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.0874 - val_accuracy: 0.9766\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 1s 112ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0834 - val_accuracy: 0.9779\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0873 - val_accuracy: 0.9782\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0871 - val_accuracy: 0.9777\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0884 - val_accuracy: 0.9784\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.0894 - val_accuracy: 0.9771\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0879 - val_accuracy: 0.9782\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 2s 145ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0906 - val_accuracy: 0.9786\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0908 - val_accuracy: 0.9785\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 2s 170ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0923 - val_accuracy: 0.9786\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 2s 199ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0914 - val_accuracy: 0.9791\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 2s 125ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0975 - val_accuracy: 0.9773\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0926 - val_accuracy: 0.9789\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0942 - val_accuracy: 0.9785\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0949 - val_accuracy: 0.9787\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0952 - val_accuracy: 0.9786\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0984 - val_accuracy: 0.9783\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0999 - val_accuracy: 0.9772\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 2s 159ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0984 - val_accuracy: 0.9787\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 2s 143ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0995 - val_accuracy: 0.9785\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0809 - accuracy: 0.9811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqB5VOKoPcAl",
        "outputId": "fe2e8d9a-f210-4eaa-9024-0eb1a8f419ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration 1:\n",
            "Test Accuracy: 0.9796000123023987\n",
            "----------\n",
            "Configuration 2:\n",
            "Test Accuracy: 0.9811000227928162\n"
          ]
        }
      ],
      "source": [
        "print(\"Configuration 1:\")\n",
        "print(f\"Test Accuracy: {test_accuracy1}\")\n",
        "print(\"----------\")\n",
        "print(\"Configuration 2:\")\n",
        "print(f\"Test Accuracy: {test_accuracy2}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}